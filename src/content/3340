A diffuser SVP 

Merci 



Bonjour, 

C'est avec grand plaisir que je vous invite à ma soutenance de thèse intitulée "Services de répartition de charge pour le Cloud: Application au traitement de données multimédia". 
La soutenance se déroulera à l'ISEP, le mardi 10 décembre 2013 à 13h30 en salle N38. Vous êtes également conviés au pot qui suivra. 

La soutenance sera en Français. 

Les membres du jury sont: 
Mme. MORIN Christine, INRIA-IRISA, Rennes, Rapporteur 
M. PIERSON Jean-Marc, IRIT, Université Paul Sabatier, Toulouse, Rapporteur 
M. ROOSE Philippe, LIUPPA, Pau, Examinateur 
M. PAWLAK Renaud, IDCapture, Paris, Examinateur 
M. SENS Pierre, LIP6 UPMC, Paris, Examinateur 
Mme. SAILHAN Françoise, CEDRIC-CNAM, Paris, Examinateur 

Mme CHIKY, Raja, LISITE-ISEP, Paris, Encadrant 
Mr GRESSIER-SOUDAN, Eric, CEDRIC-CNAM, Paris, Directeur de thèse 

Résumé de la thèse: 
------------------------------------------------------------------------------------------------------------------ 
Les progrès conjugués de l'algorithmique et des infrastructures informatiques permettent aujourd'hui d'extraire de plus en plus d'informations pertinentes et utiles des données issues de réseaux de capteurs ou de services web. Ces plateformes de traitement de données "massives" sont confrontées à plusieurs problèmes. Un problème de répartition des données: le stockage de ces grandes quantités de données impose l'agrégation de la capacité de stockage de plusieurs machines. De là découle une seconde problématique: les traitements à effectuer sur ces données doivent être à leur tour répartis efficacement de manière à ne surcharger ni les réseaux, ni les machines. 

Le travail de recherche mené dans cette thèse consiste à développer de nouveaux algorithmes de répartition de charge pour les systèmes logiciels de traitement de données massives. Le premier algorithme mis au point, nommé "WACA" (Workload and Cache Aware Algorithm) améliore le temps d'exécution des traitements en se basant sur des résumés des contenus stockés sur les machines. Le second algorithme appelé "CAWA" (Cost Aware Algorithm) tire partie de l'information de coût disponible dans les plateformes de type "Cloud Computing" en étudiant l'historique d'exécution des services. 

L'évaluation de ces algorithmes a nécessité le développement d'un simulateur d'infrastructures de "Cloud" nommé Simizer, afin de permettre leur test avant le déploiement en conditions réelles. Ce déploiement peut se faire de manière transparente grâce au système de distribution et de surveillance de service web nommé "Cloudizer", développé aussi dans le cadre de cette thèse, qui a servi à l'évaluation des algorithmes sur l'Elastic Compute Cloud d'Amazon. 

Ces travaux s'inscrivent dans le cadre du projet de plateforme de traitement de données Multimédia for Machine to Machine (MCube). Ce projet requiert une infrastructure logicielle adaptée au stockage et au traitement d'une grande quantité de photos et de sons, issus de divers réseaux de capteurs. La spécificité des traitements utilisés dans ce projet a nécessité le développement d'un service d'adaptation automatisé des programmes vers leur environnement d'exécution. 
------------------------------------------------------------------------------------------------------------------ 

En anglais 
------------------------------------------------------------------------------------------------------------------ 
Nowadays, progresses in algorithmics and computing infrastructures allow to extract more and more adequate and useful information from sensor networks or web services data. These big data computing platforms have to face several challenges. A data partitioning issue; storage of large volumes imposes aggregating several machines capacity. From this problem arises a second issue: to compute these data, tasks must be distributed efficiently in order to avoid overloading networks and machines capacities. 

The research work carried in this thesis consists in developping new load balancing algorithms for big data computing software. The first designed algorithm, named WACA (Workload And Cache Aware algorithm) enhances computing latency by using summaries for locating data in the system. The second algorithm, named CAWA for "Cost AWare Algorithm", takes advantage of cost information available on so-called "Cloud Computing" platforms by studying services execution history. 

Performance evaluation of these algorithms required designing a Cloud Infrastructure simulator named "Simizer", to allow testing prior to real setting deployment. This deployement can be carried out transparently thanks to a web service monitoring and distribution framework called "Cloudizer", also developped during this thesis work and was used to assess these algorithms on the Amazon Elastic Compute Cloud platform. 

These works are set in the context of data computing platform project called "Multimedia for Machine to Machine" (MCube). This project requires a software infrastructure fit to store and compute a large volume of pictures and sounds, collected from sensors. The specifics of the data computing programs used in this project required the development of an automated execution environement adaptation service. 
------------------------------------------------------------------------------------------------------------------ 

Mots-clés: 
Répartition de charge, Cloud, Données Massives, Filtres de Bloom 


Cordialement, 
Sylvain Lefebvre 
LISITE ISEP, 
28, rue Notre-Dame des Champs, 
75006 PARIS 




-- 

Raja CHIKY 

