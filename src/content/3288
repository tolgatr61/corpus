Bonjour,

J'ai le plaisir et l'honneur de vous inviter à la soutenance publique de 
ma thèse de Doctorat en Informatique, intitulée: "Conceptual Feature 
Extraction from Texts: Document Structuring and Categorization"
qui aura lieu le *jeudi  21 Aout 2014 à 12h* dans la salle des 
conférences du Département des Sciences de l'Informatique.

Bien Cordialement,
Fathi Ferjani

Le jury de soutenance sera composé de:

Mr. Khaled BSAIES Professeur, FST,  Tunis: Président
Mr. Mathieu ROCHE Directeur de recherches, CEMAGREF, France: Rapporteur
Mr. Mohamed Mohsen GAMMOUDI Professeur, ISAMM, Tunis: Rapporteur
Mr. Nejib HADJ ALOUANE Professeur, ENIT, Tunis: Examinateur
Mr. Sadok Ben Yahia Professeur, FST, Tunis: Directeur de thèse
Mr. Ali JAOUA, Professeur, Qatar University, co-directeur
Mr. Samir ELLUOMI, Maitre-assistant, co-encadrant

Titre: Conceptual Feature Extraction from Texts: Document Structuring 
and Categorization

Mots clés : Analyse de concepts formels, couverture conceptuelle, 
réduction de la dimensionnalité, étiquette isolée, étiquette composée 
isolée, hyper-concept
Résumé:


Text Mining ou fouille de textes (TM) permet de découvrir  des 
informations "importantes" à partir d'un corpus constitué de données 
textuelles. Ces informations peuvent être utilisées pour la 
catégorisation automatique des documents selon les thèmes, la détection 
des avis dans le cadre du web social, la sécurité et la lutte contre le 
terrorisme, etc.
La qualité des informations découvertes par les techniques du TM est un 
élément primordial pour un usage efficace et diversifié. En effet, TM 
fait face à plusieurs défis notamment (i) la complexité et l'ambiguïté 
du Traitement du Langage Naturel (TLN); et (ii) le volume colossal de 
données textuelles qui ne cesse de s'accroître tous les jours, etc.
  Dans le cadre de cette thèse, nous proposons une phase de 
pré-traitement qui tient compte de l'aspect sémantique du texte et la 
corrélation entre les mots afin d'en réduire l'ambiguïté 
d'interprétation selon leur contexte au sein du document. Pour faire 
face au problème de l'accroissement continu du volume de données, nous 
avons recours à la réduction de la dimensionnalité (DR) connue sous le 
nom de "malédiction de la dimension". DR est le processus de 
transformation d'un volume important de données textuelles dans une 
représentation minimale, moins bruyante qui aide à déterminer quels mots 
dans un document décrivent le mieux son contenu.
Fondamentalement, nous avons quatre principales contributions. Dans la 
première contribution, nous incluons les aspects sémantiques des 
documents textuels nécessitant une phase de pré-traitement afin 
d'obtenir une représentation sémantique de documents textuels 
non-structurés. Nous avons essentiellement mis l'accent sur les 
techniques entièrement non-structurées. L'objectif est de relier les 
termes spécifiques à un domaine donné en utilisant l'ontologie Word-Net  
(i.e., pour résoudre les problèmes de synonymes et hyponymes) et "part 
of speech tagging" (POS) pour déterminer les aspects grammaticaux des 
mots impliqués dans un corpus donné. Cela implique la spécification du 
groupe de mots qui sont adjacents et intimement liés.
Après la phase de raffinement des documents textuels, ces données 
peuvent être mappées dans un espace de dimension réduite. De cela, nous 
proposons une nouvelle heuristique pour identifier un sous-ensemble de 
concepts où chacun contient des mots simples, ou des mots composés 
(i.e., également appelé propriétés composées), appartenant à une seule 
notion. Cette contribution se concentre sur la réduction de la 
dimensionnalité des données et générer des étiquettes efficaces qui 
couvrent les données textuelles traitées. Malheureusement, la grande 
complexité des concepts extraits est encore élevée. Donc, étant donné 
qu'il existe une corrélation entre les points isolés et les générateurs 
minimaux, nous proposons une amélioration de la précédente. Son objectif 
principal est de réduire la complexité de temps tout en préservant un 
niveau de cohésion élevé. Enfin, les principaux inconvénients des 
solutions proposées sont affectés par l'absence de liaisons sémantiques 
entre les concepts extraits. Pour cette raison, nous proposons notre 
dernière approche qui se prête avec des termes interdépendants dans un 
document textuel donné. Dans cette thèse, nous proposons une "approche 
Hyper-conceptuelle", qui définit les liens entre les termes dans une 
structure hiérarchique dans l'ordre décroissant de leur importance. Pour 
conclure, nous présentons les principales difficultés rencontrées, les 
solutions proposées pour remédier à ces lacunes et nous décrivons les 
orientations des récentes recherches dans ce domaine.


